{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set stats:\n",
      "12877 samples spanning 120 classes (avg 107.308333 per class)\n",
      "Testing set stats:\n",
      "9249 samples spanning 120 classes (avg 77.075000 per class)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kongdol\\.conda\\envs\\coatnet\\lib\\site-packages\\torch\\functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\TensorShape.cpp:2228.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dogs import dogs\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchinfo import summary\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import copy\n",
    "from scipy import io\n",
    "# from tqdm.notebook import tqdm\n",
    "from coatnet import *\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "import time\n",
    "import os\n",
    "\n",
    "plt.ion()\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "def load_datasets(input_size=224):\n",
    "    train_transforms = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "    train_dataset = dogs(root=\"./data\",\n",
    "                         train=True,\n",
    "                         cropped=True,\n",
    "                         transform=train_transforms,\n",
    "                         download=False)\n",
    "    test_dataset = dogs(root=\"./data\",\n",
    "                        train=False,\n",
    "                        cropped=True,\n",
    "                        transform=test_transform,\n",
    "                        download=False)\n",
    "\n",
    "    # combine train and test datasets\n",
    "\n",
    "    classes = train_dataset.classes\n",
    "    print(\"Training set stats:\")\n",
    "    train_dataset.stats()\n",
    "    print(\"Testing set stats:\")\n",
    "    test_dataset.stats()\n",
    "\n",
    "    return train_dataset, test_dataset, classes\n",
    "\n",
    "\n",
    "def fwd_pass(model, loader, loss_function, optimizer, train=False):\n",
    "    if train:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "\n",
    "    total_loss = 0\n",
    "    y_pred, y = [], []\n",
    "    for X, labels in loader:\n",
    "        labels = labels.type(torch.LongTensor)\n",
    "        X, labels = X.to(device), labels.to(device)\n",
    "        # ===================손실 함수 계산=====================\n",
    "        outputs = model(X)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        total_loss += loss.item()\n",
    "        # ===================학습====================\n",
    "        if train:\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        # ===============평가===============\n",
    "        with torch.no_grad():\n",
    "            y_hat = outputs.argmax(dim=1)\n",
    "            y_pred.extend(y_hat.cpu().numpy().tolist())\n",
    "            y.extend(labels.cpu().numpy().tolist())\n",
    "\n",
    "    with torch.no_grad():\n",
    "        total_loss /= len(loader.dataset)\n",
    "        acc = accuracy_score(y, y_pred) * 100\n",
    "        f1 = f1_score(y, y_pred, average=\"weighted\") * 100\n",
    "\n",
    "    return total_loss, acc, f1\n",
    "\n",
    "\n",
    "logs = dict(trainlosses=list(), testlosses=list(),\n",
    "            trainaccs=list(), testaccs=list())\n",
    "\n",
    "\n",
    "def timeSince(since: float) -> str:\n",
    "    s = time.time() - since\n",
    "    return f\"{int(s / 60):2}m {int(s % 60):02}s\"\n",
    "\n",
    "\n",
    "def train(model, train_loader, test_loader,\n",
    "          optimizer, loss_function, epoch_num=1, device=device):\n",
    "    model.to(device)\n",
    "    torch.manual_seed(14)\n",
    "\n",
    "    start = time.time()\n",
    "    print(f\"Training Process Starts at {datetime.now().strftime('%H:%M:%S')} ... \")\n",
    "\n",
    "    epoch = 1\n",
    "\n",
    "    # loop over the dataset multiple times\n",
    "    while epoch <= epoch_num:\n",
    "        # Training\n",
    "        train_loss, train_acc, train_f1 = fwd_pass(model, train_loader, loss_function, optimizer, train=True)\n",
    "\n",
    "        # Testing\n",
    "        with torch.no_grad():\n",
    "            test_loss, test_acc, test_f1 = fwd_pass(model, test_loader, loss_function, optimizer,\n",
    "                                                    train=False)\n",
    "\n",
    "        reset = '\\n' if epoch <= 5 or epoch % 5 == 0 else '\\r'\n",
    "        print(f\"Epoch[{epoch:2d}]>>>\",\n",
    "              f\"Train/Test loss: {train_loss:.7f}/{test_loss:.7f},\",\n",
    "              f\"Acc.: {train_acc:.2f}/{test_acc:.2f}\",\n",
    "              f\"[[{timeSince(start)}]]\", end=reset)\n",
    "\n",
    "        # ===================log========================\n",
    "        logs['trainlosses'].append(train_loss)\n",
    "        logs['trainaccs'].append(train_acc)\n",
    "        logs['testlosses'].append(test_loss)\n",
    "        logs['testaccs'].append(test_acc)\n",
    "\n",
    "        epoch += 1\n",
    "\n",
    "    print(f'F1 Score: {test_f1}')\n",
    "    print(f'Finished in {timeSince(start)}')\n",
    "    return logs\n",
    "\n",
    "\n",
    "train_data, test_data, classes = load_datasets(224)\n",
    "dataset_sizes = train_data.__len__()\n",
    "batch_size = 16\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=1, shuffle=False, num_workers=0)\n",
    "\n",
    "num_blocks = [2, 2, 6, 12, 2]  # L\n",
    "channels = [64, 96, 192, 384, 768]  # D\n",
    "block_types = ['C', 'C', 'T', 'T']\n",
    "\n",
    "model = CoAtNet((224, 224), 3, num_blocks, channels, num_classes=len(classes), block_types=block_types)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate = 1e-3\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "# exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "summary(model, input_size=(batch_size, 3, 224, 224))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "CoAtNet(\n  (s0): Sequential(\n    (0): Sequential(\n      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): GELU()\n    )\n    (1): Sequential(\n      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): GELU()\n    )\n  )\n  (s1): Sequential(\n    (0): MBConv(\n      (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n      (proj): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (conv): PreNorm(\n        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (fn): Sequential(\n          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): GELU()\n          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (5): GELU()\n          (6): SE(\n            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n            (fc): Sequential(\n              (0): Linear(in_features=256, out_features=16, bias=False)\n              (1): GELU()\n              (2): Linear(in_features=16, out_features=256, bias=False)\n              (3): Sigmoid()\n            )\n          )\n          (7): Conv2d(256, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (8): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n    )\n    (1): MBConv(\n      (conv): PreNorm(\n        (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (fn): Sequential(\n          (0): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): GELU()\n          (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n          (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (5): GELU()\n          (6): SE(\n            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n            (fc): Sequential(\n              (0): Linear(in_features=384, out_features=24, bias=False)\n              (1): GELU()\n              (2): Linear(in_features=24, out_features=384, bias=False)\n              (3): Sigmoid()\n            )\n          )\n          (7): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (8): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n    )\n  )\n  (s2): Sequential(\n    (0): MBConv(\n      (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n      (proj): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (conv): PreNorm(\n        (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (fn): Sequential(\n          (0): Conv2d(96, 384, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): GELU()\n          (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n          (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (5): GELU()\n          (6): SE(\n            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n            (fc): Sequential(\n              (0): Linear(in_features=384, out_features=24, bias=False)\n              (1): GELU()\n              (2): Linear(in_features=24, out_features=384, bias=False)\n              (3): Sigmoid()\n            )\n          )\n          (7): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (8): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n    )\n    (1): MBConv(\n      (conv): PreNorm(\n        (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (fn): Sequential(\n          (0): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): GELU()\n          (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n          (4): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (5): GELU()\n          (6): SE(\n            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n            (fc): Sequential(\n              (0): Linear(in_features=768, out_features=48, bias=False)\n              (1): GELU()\n              (2): Linear(in_features=48, out_features=768, bias=False)\n              (3): Sigmoid()\n            )\n          )\n          (7): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (8): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n    )\n    (2): MBConv(\n      (conv): PreNorm(\n        (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (fn): Sequential(\n          (0): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): GELU()\n          (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n          (4): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (5): GELU()\n          (6): SE(\n            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n            (fc): Sequential(\n              (0): Linear(in_features=768, out_features=48, bias=False)\n              (1): GELU()\n              (2): Linear(in_features=48, out_features=768, bias=False)\n              (3): Sigmoid()\n            )\n          )\n          (7): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (8): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n    )\n    (3): MBConv(\n      (conv): PreNorm(\n        (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (fn): Sequential(\n          (0): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): GELU()\n          (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n          (4): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (5): GELU()\n          (6): SE(\n            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n            (fc): Sequential(\n              (0): Linear(in_features=768, out_features=48, bias=False)\n              (1): GELU()\n              (2): Linear(in_features=48, out_features=768, bias=False)\n              (3): Sigmoid()\n            )\n          )\n          (7): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (8): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n    )\n    (4): MBConv(\n      (conv): PreNorm(\n        (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (fn): Sequential(\n          (0): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): GELU()\n          (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n          (4): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (5): GELU()\n          (6): SE(\n            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n            (fc): Sequential(\n              (0): Linear(in_features=768, out_features=48, bias=False)\n              (1): GELU()\n              (2): Linear(in_features=48, out_features=768, bias=False)\n              (3): Sigmoid()\n            )\n          )\n          (7): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (8): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n    )\n    (5): MBConv(\n      (conv): PreNorm(\n        (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (fn): Sequential(\n          (0): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): GELU()\n          (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n          (4): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (5): GELU()\n          (6): SE(\n            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n            (fc): Sequential(\n              (0): Linear(in_features=768, out_features=48, bias=False)\n              (1): GELU()\n              (2): Linear(in_features=48, out_features=768, bias=False)\n              (3): Sigmoid()\n            )\n          )\n          (7): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (8): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n    )\n  )\n  (s3): Sequential(\n    (0): Transformer(\n      (pool1): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n      (pool2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n      (proj): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (attn): Sequential(\n        (0): Rearrange('b c ih iw -> b (ih iw) c')\n        (1): PreNorm(\n          (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n          (fn): Attention(\n            (attend): Softmax(dim=-1)\n            (to_qkv): Linear(in_features=192, out_features=768, bias=False)\n            (to_out): Sequential(\n              (0): Linear(in_features=256, out_features=384, bias=True)\n              (1): Dropout(p=0.0, inplace=False)\n            )\n          )\n        )\n        (2): Rearrange('b (ih iw) c -> b c ih iw', ih=14, iw=14)\n      )\n      (ff): Sequential(\n        (0): Rearrange('b c ih iw -> b (ih iw) c')\n        (1): PreNorm(\n          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (fn): FeedForward(\n            (net): Sequential(\n              (0): Linear(in_features=384, out_features=768, bias=True)\n              (1): GELU()\n              (2): Dropout(p=0.0, inplace=False)\n              (3): Linear(in_features=768, out_features=384, bias=True)\n              (4): Dropout(p=0.0, inplace=False)\n            )\n          )\n        )\n        (2): Rearrange('b (ih iw) c -> b c ih iw', ih=14, iw=14)\n      )\n    )\n    (1): Transformer(\n      (attn): Sequential(\n        (0): Rearrange('b c ih iw -> b (ih iw) c')\n        (1): PreNorm(\n          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (fn): Attention(\n            (attend): Softmax(dim=-1)\n            (to_qkv): Linear(in_features=384, out_features=768, bias=False)\n            (to_out): Sequential(\n              (0): Linear(in_features=256, out_features=384, bias=True)\n              (1): Dropout(p=0.0, inplace=False)\n            )\n          )\n        )\n        (2): Rearrange('b (ih iw) c -> b c ih iw', ih=14, iw=14)\n      )\n      (ff): Sequential(\n        (0): Rearrange('b c ih iw -> b (ih iw) c')\n        (1): PreNorm(\n          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (fn): FeedForward(\n            (net): Sequential(\n              (0): Linear(in_features=384, out_features=1536, bias=True)\n              (1): GELU()\n              (2): Dropout(p=0.0, inplace=False)\n              (3): Linear(in_features=1536, out_features=384, bias=True)\n              (4): Dropout(p=0.0, inplace=False)\n            )\n          )\n        )\n        (2): Rearrange('b (ih iw) c -> b c ih iw', ih=14, iw=14)\n      )\n    )\n    (2): Transformer(\n      (attn): Sequential(\n        (0): Rearrange('b c ih iw -> b (ih iw) c')\n        (1): PreNorm(\n          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (fn): Attention(\n            (attend): Softmax(dim=-1)\n            (to_qkv): Linear(in_features=384, out_features=768, bias=False)\n            (to_out): Sequential(\n              (0): Linear(in_features=256, out_features=384, bias=True)\n              (1): Dropout(p=0.0, inplace=False)\n            )\n          )\n        )\n        (2): Rearrange('b (ih iw) c -> b c ih iw', ih=14, iw=14)\n      )\n      (ff): Sequential(\n        (0): Rearrange('b c ih iw -> b (ih iw) c')\n        (1): PreNorm(\n          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (fn): FeedForward(\n            (net): Sequential(\n              (0): Linear(in_features=384, out_features=1536, bias=True)\n              (1): GELU()\n              (2): Dropout(p=0.0, inplace=False)\n              (3): Linear(in_features=1536, out_features=384, bias=True)\n              (4): Dropout(p=0.0, inplace=False)\n            )\n          )\n        )\n        (2): Rearrange('b (ih iw) c -> b c ih iw', ih=14, iw=14)\n      )\n    )\n    (3): Transformer(\n      (attn): Sequential(\n        (0): Rearrange('b c ih iw -> b (ih iw) c')\n        (1): PreNorm(\n          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (fn): Attention(\n            (attend): Softmax(dim=-1)\n            (to_qkv): Linear(in_features=384, out_features=768, bias=False)\n            (to_out): Sequential(\n              (0): Linear(in_features=256, out_features=384, bias=True)\n              (1): Dropout(p=0.0, inplace=False)\n            )\n          )\n        )\n        (2): Rearrange('b (ih iw) c -> b c ih iw', ih=14, iw=14)\n      )\n      (ff): Sequential(\n        (0): Rearrange('b c ih iw -> b (ih iw) c')\n        (1): PreNorm(\n          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (fn): FeedForward(\n            (net): Sequential(\n              (0): Linear(in_features=384, out_features=1536, bias=True)\n              (1): GELU()\n              (2): Dropout(p=0.0, inplace=False)\n              (3): Linear(in_features=1536, out_features=384, bias=True)\n              (4): Dropout(p=0.0, inplace=False)\n            )\n          )\n        )\n        (2): Rearrange('b (ih iw) c -> b c ih iw', ih=14, iw=14)\n      )\n    )\n    (4): Transformer(\n      (attn): Sequential(\n        (0): Rearrange('b c ih iw -> b (ih iw) c')\n        (1): PreNorm(\n          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (fn): Attention(\n            (attend): Softmax(dim=-1)\n            (to_qkv): Linear(in_features=384, out_features=768, bias=False)\n            (to_out): Sequential(\n              (0): Linear(in_features=256, out_features=384, bias=True)\n              (1): Dropout(p=0.0, inplace=False)\n            )\n          )\n        )\n        (2): Rearrange('b (ih iw) c -> b c ih iw', ih=14, iw=14)\n      )\n      (ff): Sequential(\n        (0): Rearrange('b c ih iw -> b (ih iw) c')\n        (1): PreNorm(\n          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (fn): FeedForward(\n            (net): Sequential(\n              (0): Linear(in_features=384, out_features=1536, bias=True)\n              (1): GELU()\n              (2): Dropout(p=0.0, inplace=False)\n              (3): Linear(in_features=1536, out_features=384, bias=True)\n              (4): Dropout(p=0.0, inplace=False)\n            )\n          )\n        )\n        (2): Rearrange('b (ih iw) c -> b c ih iw', ih=14, iw=14)\n      )\n    )\n    (5): Transformer(\n      (attn): Sequential(\n        (0): Rearrange('b c ih iw -> b (ih iw) c')\n        (1): PreNorm(\n          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (fn): Attention(\n            (attend): Softmax(dim=-1)\n            (to_qkv): Linear(in_features=384, out_features=768, bias=False)\n            (to_out): Sequential(\n              (0): Linear(in_features=256, out_features=384, bias=True)\n              (1): Dropout(p=0.0, inplace=False)\n            )\n          )\n        )\n        (2): Rearrange('b (ih iw) c -> b c ih iw', ih=14, iw=14)\n      )\n      (ff): Sequential(\n        (0): Rearrange('b c ih iw -> b (ih iw) c')\n        (1): PreNorm(\n          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (fn): FeedForward(\n            (net): Sequential(\n              (0): Linear(in_features=384, out_features=1536, bias=True)\n              (1): GELU()\n              (2): Dropout(p=0.0, inplace=False)\n              (3): Linear(in_features=1536, out_features=384, bias=True)\n              (4): Dropout(p=0.0, inplace=False)\n            )\n          )\n        )\n        (2): Rearrange('b (ih iw) c -> b c ih iw', ih=14, iw=14)\n      )\n    )\n    (6): Transformer(\n      (attn): Sequential(\n        (0): Rearrange('b c ih iw -> b (ih iw) c')\n        (1): PreNorm(\n          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (fn): Attention(\n            (attend): Softmax(dim=-1)\n            (to_qkv): Linear(in_features=384, out_features=768, bias=False)\n            (to_out): Sequential(\n              (0): Linear(in_features=256, out_features=384, bias=True)\n              (1): Dropout(p=0.0, inplace=False)\n            )\n          )\n        )\n        (2): Rearrange('b (ih iw) c -> b c ih iw', ih=14, iw=14)\n      )\n      (ff): Sequential(\n        (0): Rearrange('b c ih iw -> b (ih iw) c')\n        (1): PreNorm(\n          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (fn): FeedForward(\n            (net): Sequential(\n              (0): Linear(in_features=384, out_features=1536, bias=True)\n              (1): GELU()\n              (2): Dropout(p=0.0, inplace=False)\n              (3): Linear(in_features=1536, out_features=384, bias=True)\n              (4): Dropout(p=0.0, inplace=False)\n            )\n          )\n        )\n        (2): Rearrange('b (ih iw) c -> b c ih iw', ih=14, iw=14)\n      )\n    )\n    (7): Transformer(\n      (attn): Sequential(\n        (0): Rearrange('b c ih iw -> b (ih iw) c')\n        (1): PreNorm(\n          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (fn): Attention(\n            (attend): Softmax(dim=-1)\n            (to_qkv): Linear(in_features=384, out_features=768, bias=False)\n            (to_out): Sequential(\n              (0): Linear(in_features=256, out_features=384, bias=True)\n              (1): Dropout(p=0.0, inplace=False)\n            )\n          )\n        )\n        (2): Rearrange('b (ih iw) c -> b c ih iw', ih=14, iw=14)\n      )\n      (ff): Sequential(\n        (0): Rearrange('b c ih iw -> b (ih iw) c')\n        (1): PreNorm(\n          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (fn): FeedForward(\n            (net): Sequential(\n              (0): Linear(in_features=384, out_features=1536, bias=True)\n              (1): GELU()\n              (2): Dropout(p=0.0, inplace=False)\n              (3): Linear(in_features=1536, out_features=384, bias=True)\n              (4): Dropout(p=0.0, inplace=False)\n            )\n          )\n        )\n        (2): Rearrange('b (ih iw) c -> b c ih iw', ih=14, iw=14)\n      )\n    )\n    (8): Transformer(\n      (attn): Sequential(\n        (0): Rearrange('b c ih iw -> b (ih iw) c')\n        (1): PreNorm(\n          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (fn): Attention(\n            (attend): Softmax(dim=-1)\n            (to_qkv): Linear(in_features=384, out_features=768, bias=False)\n            (to_out): Sequential(\n              (0): Linear(in_features=256, out_features=384, bias=True)\n              (1): Dropout(p=0.0, inplace=False)\n            )\n          )\n        )\n        (2): Rearrange('b (ih iw) c -> b c ih iw', ih=14, iw=14)\n      )\n      (ff): Sequential(\n        (0): Rearrange('b c ih iw -> b (ih iw) c')\n        (1): PreNorm(\n          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (fn): FeedForward(\n            (net): Sequential(\n              (0): Linear(in_features=384, out_features=1536, bias=True)\n              (1): GELU()\n              (2): Dropout(p=0.0, inplace=False)\n              (3): Linear(in_features=1536, out_features=384, bias=True)\n              (4): Dropout(p=0.0, inplace=False)\n            )\n          )\n        )\n        (2): Rearrange('b (ih iw) c -> b c ih iw', ih=14, iw=14)\n      )\n    )\n    (9): Transformer(\n      (attn): Sequential(\n        (0): Rearrange('b c ih iw -> b (ih iw) c')\n        (1): PreNorm(\n          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (fn): Attention(\n            (attend): Softmax(dim=-1)\n            (to_qkv): Linear(in_features=384, out_features=768, bias=False)\n            (to_out): Sequential(\n              (0): Linear(in_features=256, out_features=384, bias=True)\n              (1): Dropout(p=0.0, inplace=False)\n            )\n          )\n        )\n        (2): Rearrange('b (ih iw) c -> b c ih iw', ih=14, iw=14)\n      )\n      (ff): Sequential(\n        (0): Rearrange('b c ih iw -> b (ih iw) c')\n        (1): PreNorm(\n          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (fn): FeedForward(\n            (net): Sequential(\n              (0): Linear(in_features=384, out_features=1536, bias=True)\n              (1): GELU()\n              (2): Dropout(p=0.0, inplace=False)\n              (3): Linear(in_features=1536, out_features=384, bias=True)\n              (4): Dropout(p=0.0, inplace=False)\n            )\n          )\n        )\n        (2): Rearrange('b (ih iw) c -> b c ih iw', ih=14, iw=14)\n      )\n    )\n    (10): Transformer(\n      (attn): Sequential(\n        (0): Rearrange('b c ih iw -> b (ih iw) c')\n        (1): PreNorm(\n          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (fn): Attention(\n            (attend): Softmax(dim=-1)\n            (to_qkv): Linear(in_features=384, out_features=768, bias=False)\n            (to_out): Sequential(\n              (0): Linear(in_features=256, out_features=384, bias=True)\n              (1): Dropout(p=0.0, inplace=False)\n            )\n          )\n        )\n        (2): Rearrange('b (ih iw) c -> b c ih iw', ih=14, iw=14)\n      )\n      (ff): Sequential(\n        (0): Rearrange('b c ih iw -> b (ih iw) c')\n        (1): PreNorm(\n          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (fn): FeedForward(\n            (net): Sequential(\n              (0): Linear(in_features=384, out_features=1536, bias=True)\n              (1): GELU()\n              (2): Dropout(p=0.0, inplace=False)\n              (3): Linear(in_features=1536, out_features=384, bias=True)\n              (4): Dropout(p=0.0, inplace=False)\n            )\n          )\n        )\n        (2): Rearrange('b (ih iw) c -> b c ih iw', ih=14, iw=14)\n      )\n    )\n    (11): Transformer(\n      (attn): Sequential(\n        (0): Rearrange('b c ih iw -> b (ih iw) c')\n        (1): PreNorm(\n          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (fn): Attention(\n            (attend): Softmax(dim=-1)\n            (to_qkv): Linear(in_features=384, out_features=768, bias=False)\n            (to_out): Sequential(\n              (0): Linear(in_features=256, out_features=384, bias=True)\n              (1): Dropout(p=0.0, inplace=False)\n            )\n          )\n        )\n        (2): Rearrange('b (ih iw) c -> b c ih iw', ih=14, iw=14)\n      )\n      (ff): Sequential(\n        (0): Rearrange('b c ih iw -> b (ih iw) c')\n        (1): PreNorm(\n          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (fn): FeedForward(\n            (net): Sequential(\n              (0): Linear(in_features=384, out_features=1536, bias=True)\n              (1): GELU()\n              (2): Dropout(p=0.0, inplace=False)\n              (3): Linear(in_features=1536, out_features=384, bias=True)\n              (4): Dropout(p=0.0, inplace=False)\n            )\n          )\n        )\n        (2): Rearrange('b (ih iw) c -> b c ih iw', ih=14, iw=14)\n      )\n    )\n  )\n  (s4): Sequential(\n    (0): Transformer(\n      (pool1): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n      (pool2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n      (proj): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (attn): Sequential(\n        (0): Rearrange('b c ih iw -> b (ih iw) c')\n        (1): PreNorm(\n          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (fn): Attention(\n            (attend): Softmax(dim=-1)\n            (to_qkv): Linear(in_features=384, out_features=768, bias=False)\n            (to_out): Sequential(\n              (0): Linear(in_features=256, out_features=768, bias=True)\n              (1): Dropout(p=0.0, inplace=False)\n            )\n          )\n        )\n        (2): Rearrange('b (ih iw) c -> b c ih iw', ih=7, iw=7)\n      )\n      (ff): Sequential(\n        (0): Rearrange('b c ih iw -> b (ih iw) c')\n        (1): PreNorm(\n          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (fn): FeedForward(\n            (net): Sequential(\n              (0): Linear(in_features=768, out_features=1536, bias=True)\n              (1): GELU()\n              (2): Dropout(p=0.0, inplace=False)\n              (3): Linear(in_features=1536, out_features=768, bias=True)\n              (4): Dropout(p=0.0, inplace=False)\n            )\n          )\n        )\n        (2): Rearrange('b (ih iw) c -> b c ih iw', ih=7, iw=7)\n      )\n    )\n    (1): Transformer(\n      (attn): Sequential(\n        (0): Rearrange('b c ih iw -> b (ih iw) c')\n        (1): PreNorm(\n          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (fn): Attention(\n            (attend): Softmax(dim=-1)\n            (to_qkv): Linear(in_features=768, out_features=768, bias=False)\n            (to_out): Sequential(\n              (0): Linear(in_features=256, out_features=768, bias=True)\n              (1): Dropout(p=0.0, inplace=False)\n            )\n          )\n        )\n        (2): Rearrange('b (ih iw) c -> b c ih iw', ih=7, iw=7)\n      )\n      (ff): Sequential(\n        (0): Rearrange('b c ih iw -> b (ih iw) c')\n        (1): PreNorm(\n          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (fn): FeedForward(\n            (net): Sequential(\n              (0): Linear(in_features=768, out_features=3072, bias=True)\n              (1): GELU()\n              (2): Dropout(p=0.0, inplace=False)\n              (3): Linear(in_features=3072, out_features=768, bias=True)\n              (4): Dropout(p=0.0, inplace=False)\n            )\n          )\n        )\n        (2): Rearrange('b (ih iw) c -> b c ih iw', ih=7, iw=7)\n      )\n    )\n  )\n  (pool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n  (fc): Linear(in_features=768, out_features=120, bias=False)\n)"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('./savemodel/dogbreed1.pth'))\n",
    "model.to(device)\n",
    "model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Process Starts at 17:43:26 ... \n",
      "Epoch[ 1]>>> Train/Test loss: 0.0078367/0.0714398, Acc.: 95.81/97.84 [[10m 53s]]\n",
      "Epoch[ 2]>>> Train/Test loss: 0.0067343/0.0763198, Acc.: 96.58/97.63 [[21m 47s]]\n",
      "Epoch[ 3]>>> Train/Test loss: 0.0064167/0.0631362, Acc.: 96.53/98.15 [[32m 38s]]\n",
      "F1 Score: 98.15673013989462\n",
      "Finished in 32m 38s\n"
     ]
    }
   ],
   "source": [
    "logs = train(model, train_loader=train_loader, test_loader=test_loader,\n",
    "             optimizer=optimizer, loss_function=criterion,\n",
    "             epoch_num=3, device=device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "torch.save(model, './savemodel/dogbreed2.pth')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "logs = train(model, train_loader=train_loader, test_loader=test_loader,\n",
    "             optimizer=optimizer, loss_function=criterion,\n",
    "             epoch_num=10, device=device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracy of Chihuaha: 100%\n",
      "Acuracy of Japanese Spaniel: 100%\n",
      "Acuracy of Maltese Dog: 100%\n",
      "Acuracy of Pekinese: 98%\n",
      "Acuracy of Shih-Tzu: 100%\n",
      "Acuracy of Blenheim Spaniel: 100%\n",
      "Acuracy of Papillon: 100%\n",
      "Acuracy of Toy Terrier: 100%\n",
      "Acuracy of Rhodesian Ridgeback: 100%\n",
      "Acuracy of Afghan Hound: 100%\n",
      "Acuracy of Basset Hound: 100%\n",
      "Acuracy of Beagle: 100%\n",
      "Acuracy of Bloodhound: 100%\n",
      "Acuracy of Bluetick: 100%\n",
      "Acuracy of Black-and-tan Coonhound: 100%\n",
      "Acuracy of Walker Hound: 100%\n",
      "Acuracy of English Foxhound: 100%\n",
      "Acuracy of Redbone: 100%\n",
      "Acuracy of Borzoi: 100%\n",
      "Acuracy of Irish Wolfhound: 100%\n",
      "Acuracy of Italian Greyhound: 100%\n",
      "Acuracy of Whippet: 100%\n",
      "Acuracy of Ibizian Hound: 100%\n",
      "Acuracy of Norwegian Elkhound: 100%\n",
      "Acuracy of Otterhound: 100%\n",
      "Acuracy of Saluki: 100%\n",
      "Acuracy of Scottish Deerhound: 100%\n",
      "Acuracy of Weimaraner: 100%\n",
      "Acuracy of Staffordshire Bullterrier: 100%\n",
      "Acuracy of American Staffordshire Terrier: 100%\n",
      "Acuracy of Bedlington Terrier: 100%\n",
      "Acuracy of Border Terrier: 100%\n",
      "Acuracy of Kerry Blue Terrier: 100%\n",
      "Acuracy of Irish Terrier: 100%\n",
      "Acuracy of Norfolk Terrier: 100%\n",
      "Acuracy of Norwich Terrier: 100%\n",
      "Acuracy of Yorkshire Terrier: 98%\n",
      "Acuracy of Wirehaired Fox Terrier: 100%\n",
      "Acuracy of Lakeland Terrier: 100%\n",
      "Acuracy of Sealyham Terrier: 100%\n",
      "Acuracy of Airedale: 99%\n",
      "Acuracy of Cairn: 100%\n",
      "Acuracy of Australian Terrier: 100%\n",
      "Acuracy of Dandi Dinmont: 100%\n",
      "Acuracy of Boston Bull: 100%\n",
      "Acuracy of Miniature Schnauzer: 98%\n",
      "Acuracy of Giant Schnauzer: 100%\n",
      "Acuracy of Standard Schnauzer: 100%\n",
      "Acuracy of Scotch Terrier: 100%\n",
      "Acuracy of Tibetan Terrier: 100%\n",
      "Acuracy of Silky Terrier: 100%\n",
      "Acuracy of Soft-coated Wheaten Terrier: 100%\n",
      "Acuracy of West Highland White Terrier: 100%\n",
      "Acuracy of Lhasa: 100%\n",
      "Acuracy of Flat-coated Retriever: 100%\n",
      "Acuracy of Curly-coater Retriever: 100%\n",
      "Acuracy of Golden Retriever: 100%\n",
      "Acuracy of Labrador Retriever: 100%\n",
      "Acuracy of Chesapeake Bay Retriever: 100%\n",
      "Acuracy of German Short-haired Pointer: 100%\n",
      "Acuracy of Vizsla: 100%\n",
      "Acuracy of English Setter: 100%\n",
      "Acuracy of Irish Setter: 100%\n",
      "Acuracy of Gordon Setter: 100%\n",
      "Acuracy of Brittany: 100%\n",
      "Acuracy of Clumber: 100%\n",
      "Acuracy of English Springer Spaniel: 100%\n",
      "Acuracy of Welsh Springer Spaniel: 100%\n",
      "Acuracy of Cocker Spaniel: 100%\n",
      "Acuracy of Sussex Spaniel: 100%\n",
      "Acuracy of Irish Water Spaniel: 100%\n",
      "Acuracy of Kuvasz: 100%\n",
      "Acuracy of Schipperke: 100%\n",
      "Acuracy of Groenendael: 100%\n",
      "Acuracy of Malinois: 100%\n",
      "Acuracy of Briard: 98%\n",
      "Acuracy of Kelpie: 100%\n",
      "Acuracy of Komondor: 100%\n",
      "Acuracy of Old English Sheepdog: 100%\n",
      "Acuracy of Shetland Sheepdog: 100%\n",
      "Acuracy of Collie: 100%\n",
      "Acuracy of Border Collie: 100%\n",
      "Acuracy of Bouvier des Flandres: 100%\n",
      "Acuracy of Rottweiler: 100%\n",
      "Acuracy of German Shepard: 100%\n",
      "Acuracy of Doberman: 100%\n",
      "Acuracy of Miniature Pinscher: 100%\n",
      "Acuracy of Greater Swiss Mountain Dog: 100%\n",
      "Acuracy of Bernese Mountain Dog: 100%\n",
      "Acuracy of Appenzeller: 100%\n",
      "Acuracy of EntleBucher: 100%\n",
      "Acuracy of Boxer: 100%\n",
      "Acuracy of Bull Mastiff: 100%\n",
      "Acuracy of Tibetan Mastiff: 100%\n",
      "Acuracy of French Bulldog: 100%\n",
      "Acuracy of Great Dane: 100%\n",
      "Acuracy of Saint Bernard: 100%\n",
      "Acuracy of Eskimo Dog: 100%\n",
      "Acuracy of Malamute: 100%\n",
      "Acuracy of Siberian Husky: 100%\n",
      "Acuracy of Affenpinscher: 98%\n",
      "Acuracy of Basenji: 100%\n",
      "Acuracy of Pug  : 100%\n",
      "Acuracy of Leonberg: 100%\n",
      "Acuracy of Newfoundland: 100%\n",
      "Acuracy of Great Pyrenees: 100%\n",
      "Acuracy of Samoyed: 100%\n",
      "Acuracy of Pomeranian: 100%\n",
      "Acuracy of Chow : 100%\n",
      "Acuracy of Keeshond: 100%\n",
      "Acuracy of Brabancon Griffon: 98%\n",
      "Acuracy of Pembroke: 100%\n",
      "Acuracy of Cardigan: 100%\n",
      "Acuracy of Toy Poodle: 100%\n",
      "Acuracy of Miniature Poodle: 100%\n",
      "Acuracy of Standard Poodle: 98%\n",
      "Acuracy of Mexican Hairless: 100%\n",
      "Acuracy of Dingo: 100%\n",
      "Acuracy of Dhole: 100%\n",
      "Acuracy of African Hunting Dog: 100%\n"
     ]
    }
   ],
   "source": [
    "class_correct = [0.] * 120\n",
    "class_total = [0.] * 120\n",
    "y_test, y_pred = [], []\n",
    "X_test = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        X_test.extend([_ for _ in images])\n",
    "        outputs = model(images.to(device))\n",
    "        _, predicted = torch.topk(outputs, 3)\n",
    "        predicted = predicted.cpu()\n",
    "        c = (labels in predicted)\n",
    "        for i, label in enumerate(labels):\n",
    "            class_correct[label] += int(c)\n",
    "            class_total[label] += 1\n",
    "        y_pred.extend(predicted.numpy())\n",
    "        y_test.extend(labels.cpu().numpy())\n",
    "\n",
    "for i in range(120):\n",
    "    print(f\"Acuracy of {classes[i]:5s}: {100 * class_correct[i] / class_total[i]:2.0f}%\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Setter\n",
      "[61, 65, 66]\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "transformer = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "img = Image.open('./imgs/10.jpg')\n",
    "img = transformer(img)\n",
    "output = model(img.unsqueeze(0).to(device))\n",
    "print(classes[output.argmax(dim=1)])\n",
    "# print(output.topk(3))\n",
    "\n",
    "top3 = torch.topk(output, 3,dim=1)\n",
    "predict_list = [int(x) for x in top3.indices.squeeze()]\n",
    "print(predict_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Setter\n",
      "Clumber\n",
      "English Springer Spaniel\n"
     ]
    }
   ],
   "source": [
    "for i in predict_list:\n",
    "    print(f\"{classes[i]:5s}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}